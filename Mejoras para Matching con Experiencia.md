# Mejoras para Matching con Experiencia - Mayor Precisi√≥n

## üéØ Objetivo
Mejorar la precisi√≥n del algoritmo de matching para que identifique mejor las licitaciones que realmente encajan con la experiencia de la empresa.

---

## üìä An√°lisis de Limitaciones Actuales

### **1. Keywords Matching (50% del peso)**

**Problemas actuales:**
- ‚ùå Solo cuenta coincidencias exactas de palabras
- ‚ùå No considera sin√≥nimos (ej: "vial" vs "carretera" vs "v√≠as")
- ‚ùå No pondera keywords importantes vs. secundarios
- ‚ùå No entiende contexto sem√°ntico
- ‚ùå No considera orden/posici√≥n de keywords
- ‚ùå Lista de keywords limitada y est√°tica

**Ejemplo de problema:**
- Experiencia: "Interventor√≠a de carretera en Cundinamarca"
- Licitaci√≥n: "Supervisi√≥n de v√≠as en Cundinamarca"
- **Resultado actual:** Bajo match porque "carretera" ‚â† "v√≠as"
- **Deber√≠a ser:** Alto match porque son sin√≥nimos

---

### **2. Amount Matching (25% del peso)**

**Problemas actuales:**
- ‚ùå No considera inflaci√≥n (experiencias de 2000 vs 2024)
- ‚ùå Rangos fijos (0.5x-2x) pueden ser muy amplios o muy restrictivos
- ‚ùå No considera tipo de proyecto (interventor√≠a vs construcci√≥n)
- ‚ùå No diferencia entre proyectos grandes/peque√±os
- ‚ùå Score neutral (0.5) cuando falta monto puede ser enga√±oso

**Ejemplo de problema:**
- Experiencia: $100M en 2000 (con inflaci√≥n ‚âà $500M en 2024)
- Licitaci√≥n: $400M en 2024
- **Resultado actual:** Bajo match (ratio 4x)
- **Deber√≠a ser:** Alto match (considerando inflaci√≥n)

---

### **3. Entity Matching (15% del peso)**

**Problemas actuales:**
- ‚ùå Muy b√°sico, solo busca palabras comunes
- ‚ùå No normaliza nombres (INVIAS vs "Instituto Nacional de V√≠as")
- ‚ùå No considera entidades relacionadas
- ‚ùå No usa fuzzy matching para nombres similares
- ‚ùå No diferencia entre entidades principales y secundarias

**Ejemplo de problema:**
- Experiencia: "INVIAS"
- Licitaci√≥n: "Instituto Nacional de V√≠as"
- **Resultado actual:** Bajo match (0.0)
- **Deber√≠a ser:** Alto match (1.0) - misma entidad

---

### **4. Category Matching (10% del peso)**

**Problemas actuales:**
- ‚ùå Muy limitado, solo busca palabras clave
- ‚ùå No hay taxonom√≠a de categor√≠as
- ‚ùå No considera subcategor√≠as
- ‚ùå Score neutral (0.5) cuando no hay match puede sesgar resultados
- ‚ùå No diferencia entre tipos de interventor√≠a (vial, ambiental, etc.)

---

### **5. Factores Faltantes (0% del peso actual)**

**Factores importantes que NO se consideran:**
- ‚ùå **Ubicaci√≥n geogr√°fica** (departamento/municipio) - Muy importante
- ‚ùå **Fecha de experiencia** (experiencias recientes m√°s relevantes)
- ‚ùå **√âxito del proyecto** (proyectos ganados vs perdidos)
- ‚ùå **Complejidad del proyecto** (similar complejidad = mejor match)
- ‚ùå **Duraci√≥n del proyecto** (proyectos de duraci√≥n similar)

---

## üöÄ Mejoras Propuestas (Priorizadas)

### **Mejora #1: Keywords Matching Mejorado** üî• (Alta Prioridad)

#### **1.1. Sin√≥nimos y Variaciones**
```python
# Diccionario de sin√≥nimos
SYNONYMS = {
    "vial": ["v√≠as", "vias", "carretera", "malla vial", "infraestructura vial"],
    "interventor√≠a": ["interventoria", "supervisi√≥n", "supervision", "control"],
    "obra": ["obras", "construcci√≥n", "construccion", "proyecto"],
    "mantenimiento": ["conservaci√≥n", "conservacion", "rehabilitaci√≥n", "rehabilitacion"],
    # ... m√°s sin√≥nimos
}

# Al buscar keywords, tambi√©n buscar sin√≥nimos
def find_keyword_with_synonyms(keyword, text):
    if keyword in text:
        return True
    if keyword in SYNONYMS:
        for synonym in SYNONYMS[keyword]:
            if synonym in text:
                return True
    return False
```

**Impacto:** Alto - Mejora significativamente la precisi√≥n

---

#### **1.2. Ponderaci√≥n de Keywords**
```python
# Keywords m√°s importantes tienen m√°s peso
KEYWORD_WEIGHTS = {
    "interventor√≠a": 2.0,  # Muy importante
    "vial": 1.5,
    "carretera": 1.5,
    "supervisi√≥n": 1.5,
    "obra": 1.0,
    "mantenimiento": 1.0,
    # ... otros keywords con peso 1.0 por defecto
}

# Calcular score ponderado
def calculate_weighted_keyword_score(matches):
    total_weight = sum(KEYWORD_WEIGHTS.get(kw, 1.0) for kw in matches)
    max_possible_weight = sum(KEYWORD_WEIGHTS.get(kw, 1.0) for kw in all_keywords)
    return total_weight / max_possible_weight
```

**Impacto:** Alto - Prioriza keywords m√°s relevantes

---

#### **1.3. Extracci√≥n Mejorada de Keywords**
```python
# Usar NLP para extraer keywords m√°s relevantes
import nltk
from collections import Counter

def extract_keywords_advanced(text):
    # 1. Tokenizar y limpiar
    tokens = nltk.word_tokenize(text.lower())
    tokens = [t for t in tokens if t.isalpha() and len(t) > 3]
    
    # 2. Remover stop words
    stop_words = set(nltk.corpus.stopwords.words('spanish'))
    tokens = [t for t in tokens if t not in stop_words]
    
    # 3. Extraer bigramas y trigramas importantes
    bigrams = list(nltk.bigrams(tokens))
    trigrams = list(nltk.trigrams(tokens))
    
    # 4. Filtrar por frecuencia y relevancia
    # 5. Combinar con keywords t√©cnicos conocidos
    
    return relevant_keywords
```

**Impacto:** Medio - Requiere librer√≠as adicionales pero mejora calidad

---

#### **1.4. Similaridad Sem√°ntica (Opcional - Avanzado)**
```python
# Usar embeddings para similaridad sem√°ntica
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

def calculate_semantic_similarity(text1, text2):
    embeddings = model.encode([text1, text2])
    similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]
    return similarity
```

**Impacto:** Alto - Pero requiere modelo de ML, m√°s complejo

---

### **Mejora #2: Amount Matching Mejorado** üî• (Alta Prioridad)

#### **2.1. Ajuste por Inflaci√≥n**
```python
import pandas as pd

# Datos de inflaci√≥n hist√≥rica (IPC Colombia)
INFLATION_RATES = {
    2000: 5.7, 2001: 7.6, 2002: 6.2,  # ... m√°s a√±os
    2020: 1.6, 2021: 5.6, 2022: 13.1, 2023: 11.8
}

def adjust_for_inflation(amount, year_from, year_to):
    """Ajustar monto por inflaci√≥n entre dos a√±os."""
    if year_from >= year_to:
        return amount
    
    # Calcular factor de inflaci√≥n acumulado
    factor = 1.0
    for year in range(year_from + 1, year_to + 1):
        if year in INFLATION_RATES:
            factor *= (1 + INFLATION_RATES[year] / 100)
    
    return amount * factor

def calculate_amount_score_improved(tender_amount, tender_year, 
                                   experience_amount, experience_year):
    # Ajustar experiencia a a√±o actual
    adjusted_experience = adjust_for_inflation(
        experience_amount, 
        experience_year, 
        tender_year or datetime.now().year
    )
    
    # Calcular ratio con monto ajustado
    ratio = tender_amount / adjusted_experience if adjusted_experience > 0 else 0
    
    # Rangos m√°s precisos
    if 0.8 <= ratio <= 1.2:  # Muy similar (¬±20%)
        return 1.0
    elif 0.6 <= ratio <= 1.5:  # Similar (¬±50%)
        return 0.9
    elif 0.4 <= ratio <= 2.0:  # Aceptable (2x)
        return 0.7
    elif 0.2 <= ratio <= 3.0:  # Amplio (3x)
        return 0.5
    else:
        return 0.2
```

**Impacto:** Alto - Mejora significativamente matching de experiencias antiguas

---

#### **2.2. Rangos por Tipo de Proyecto**
```python
# Rangos diferentes seg√∫n tipo de proyecto
AMOUNT_RANGES_BY_TYPE = {
    "interventor√≠a": {
        "tight": (0.8, 1.2),    # ¬±20%
        "good": (0.6, 1.5),     # ¬±50%
        "acceptable": (0.4, 2.0) # 2x
    },
    "construcci√≥n": {
        "tight": (0.7, 1.3),
        "good": (0.5, 2.0),
        "acceptable": (0.3, 3.0)
    },
    # ... m√°s tipos
}
```

**Impacto:** Medio - Mejora precisi√≥n por tipo de proyecto

---

### **Mejora #3: Entity Matching Mejorado** üî• (Alta Prioridad)

#### **3.1. Normalizaci√≥n de Nombres**
```python
# Diccionario de normalizaciones comunes
ENTITY_NORMALIZATIONS = {
    "invias": ["instituto nacional de v√≠as", "instituto nacional de vias"],
    "idrd": ["instituto distrital de recreaci√≥n y deporte"],
    "idu": ["instituto de desarrollo urbano"],
    # ... m√°s normalizaciones
}

def normalize_entity_name(entity_name):
    """Normalizar nombre de entidad para matching."""
    name_lower = entity_name.lower().strip()
    
    # Buscar en normalizaciones
    for normalized, variants in ENTITY_NORMALIZATIONS.items():
        if name_lower == normalized or name_lower in variants:
            return normalized
        if any(variant in name_lower for variant in variants):
            return normalized
    
    return name_lower

def calculate_entity_score_improved(tender_entity, experience_entity):
    if not experience_entity:
        return 0.5
    
    tender_norm = normalize_entity_name(tender_entity)
    experience_norm = normalize_entity_name(experience_entity)
    
    # Exact match despu√©s de normalizaci√≥n
    if tender_norm == experience_norm:
        return 1.0
    
    # Fuzzy matching para nombres similares
    from difflib import SequenceMatcher
    similarity = SequenceMatcher(None, tender_norm, experience_norm).ratio()
    
    if similarity >= 0.9:  # Muy similar
        return 0.95
    elif similarity >= 0.7:  # Similar
        return 0.7
    elif similarity >= 0.5:  # Parcial
        return 0.4
    
    return 0.0
```

**Impacto:** Alto - Resuelve problema de nombres diferentes de misma entidad

---

#### **3.2. Fuzzy Matching Avanzado**
```python
from fuzzywuzzy import fuzz

def calculate_entity_fuzzy_score(entity1, entity2):
    # Ratio de similitud
    ratio = fuzz.ratio(entity1.lower(), entity2.lower())
    
    # Partial ratio (una contiene a la otra)
    partial = fuzz.partial_ratio(entity1.lower(), entity2.lower())
    
    # Token sort ratio (ignora orden)
    token_sort = fuzz.token_sort_ratio(entity1.lower(), entity2.lower())
    
    # Usar el mejor score
    best_score = max(ratio, partial, token_sort)
    
    # Normalizar a 0-1
    return best_score / 100.0
```

**Impacto:** Alto - Mejora matching de nombres similares

---

### **Mejora #4: Agregar Factor de Ubicaci√≥n** üî• (Alta Prioridad)

#### **4.1. Matching Geogr√°fico**
```python
def calculate_location_score(tender_dept, tender_municipality,
                            experience_dept, experience_municipality):
    """Calcular score basado en ubicaci√≥n geogr√°fica."""
    
    # Mismo municipio = match perfecto
    if tender_municipality and experience_municipality:
        if normalize_location(tender_municipality) == normalize_location(experience_municipality):
            return 1.0
    
    # Mismo departamento = buen match
    if tender_dept and experience_dept:
        if normalize_location(tender_dept) == normalize_location(experience_dept):
            return 0.8
    
    # Departamentos vecinos = match parcial
    if are_neighboring_departments(tender_dept, experience_dept):
        return 0.5
    
    # Sin match geogr√°fico
    return 0.3  # No es 0 porque puede ser match v√°lido

def normalize_location(location):
    """Normalizar nombres de ubicaciones."""
    # Remover acentos, convertir a min√∫sculas
    # "Cundinamarca" = "cundinamarca"
    # "Bogot√°" = "bogota"
    return location.lower().strip()
```

**Impacto:** Muy Alto - La ubicaci√≥n es muy importante para matching

**Nuevo peso sugerido:** 20% (agregar a los pesos existentes)

---

### **Mejora #5: Factor de Fecha de Experiencia** (Media Prioridad)

#### **5.1. Ponderaci√≥n por Antig√ºedad**
```python
def calculate_recency_weight(experience_date):
    """Calcular peso seg√∫n antig√ºedad de la experiencia."""
    if not experience_date:
        return 0.8  # Sin fecha, peso medio
    
    years_ago = (datetime.now().date() - experience_date).days / 365.25
    
    if years_ago <= 2:  # Muy reciente (√∫ltimos 2 a√±os)
        return 1.0
    elif years_ago <= 5:  # Reciente (2-5 a√±os)
        return 0.9
    elif years_ago <= 10:  # Moderado (5-10 a√±os)
        return 0.7
    else:  # Antiguo (>10 a√±os)
        return 0.5

# Aplicar peso a todos los scores
def apply_recency_weight(base_score, recency_weight):
    return base_score * recency_weight
```

**Impacto:** Medio - Experiencias recientes son m√°s relevantes

---

### **Mejora #6: Factor de √âxito del Proyecto** (Media Prioridad)

#### **6.1. Ponderaci√≥n por √âxito**
```python
# Agregar campo "was_successful" a CompanyExperience
# Si el proyecto fue ganado/completado exitosamente = m√°s relevante

def calculate_success_weight(was_successful):
    """Calcular peso seg√∫n √©xito del proyecto."""
    if was_successful is None:
        return 0.8  # Sin informaci√≥n, peso medio
    
    if was_successful:
        return 1.0  # Proyecto exitoso = m√°s relevante
    else:
        return 0.6  # Proyecto no exitoso = menos relevante
```

**Impacto:** Medio - Requiere agregar campo a modelo

---

### **Mejora #7: Category Matching Mejorado** (Media Prioridad)

#### **7.1. Taxonom√≠a de Categor√≠as**
```python
# Taxonom√≠a jer√°rquica de categor√≠as
CATEGORY_TAXONOMY = {
    "interventor√≠a": {
        "vial": ["carretera", "v√≠as", "malla vial", "infraestructura vial"],
        "ambiental": ["medio ambiente", "ambiental", "sostenibilidad"],
        "construcci√≥n": ["obra", "construcci√≥n", "edificaci√≥n"],
        # ... m√°s subcategor√≠as
    },
    "supervisi√≥n": {
        "t√©cnica": ["t√©cnica", "ingenier√≠a"],
        "administrativa": ["administrativa", "gesti√≥n"],
        # ... m√°s
    }
}

def calculate_category_score_improved(tender, experience):
    """Matching mejorado de categor√≠as usando taxonom√≠a."""
    if not experience.category:
        return 0.5
    
    tender_text = (tender.object_text or "").lower()
    exp_category = experience.category.lower()
    
    # Buscar en taxonom√≠a
    for main_cat, subcats in CATEGORY_TAXONOMY.items():
        if main_cat in exp_category:
            # Buscar subcategor√≠as en texto de licitaci√≥n
            for subcat, keywords in subcats.items():
                if any(kw in tender_text for kw in keywords):
                    return 1.0  # Match perfecto
    
    # Fallback a matching b√°sico
    return calculate_category_score(tender, experience)
```

**Impacto:** Medio - Mejora precisi√≥n de categor√≠as

---

## üìä Nuevos Pesos Sugeridos

### **Opci√≥n 1: Agregar Ubicaci√≥n (Recomendado)**
```python
WEIGHTS_IMPROVED = {
    "keyword": 0.40,    # Reducido de 0.50
    "amount": 0.20,     # Reducido de 0.25
    "entity": 0.15,     # Mantiene
    "category": 0.10,   # Mantiene
    "location": 0.15,   # NUEVO - Muy importante
}
```

### **Opci√≥n 2: Agregar Ubicaci√≥n + Fecha**
```python
WEIGHTS_IMPROVED = {
    "keyword": 0.35,
    "amount": 0.20,
    "entity": 0.15,
    "category": 0.10,
    "location": 0.15,   # NUEVO
    "recency": 0.05,    # NUEVO - Peso menor pero importante
}
```

---

## üéØ Plan de Implementaci√≥n Recomendado

### **Fase 1: Mejoras R√°pidas (1-2 semanas)**
1. ‚úÖ **Sin√≥nimos y variaciones** en keywords
2. ‚úÖ **Normalizaci√≥n de entidades**
3. ‚úÖ **Factor de ubicaci√≥n geogr√°fica**
4. ‚úÖ **Ajuste por inflaci√≥n** en amounts

**Impacto esperado:** +30-40% de precisi√≥n

---

### **Fase 2: Mejoras Intermedias (2-3 semanas)**
5. ‚úÖ **Ponderaci√≥n de keywords**
6. ‚úÖ **Fuzzy matching** de entidades
7. ‚úÖ **Factor de fecha** (recency)
8. ‚úÖ **Rangos por tipo de proyecto**

**Impacto esperado:** +20-30% adicional de precisi√≥n

---

### **Fase 3: Mejoras Avanzadas (3-4 semanas)**
9. ‚úÖ **NLP para extracci√≥n de keywords**
10. ‚úÖ **Taxonom√≠a de categor√≠as**
11. ‚úÖ **Factor de √©xito** (requiere datos)
12. ‚úÖ **Similaridad sem√°ntica** (opcional, requiere ML)

**Impacto esperado:** +10-20% adicional de precisi√≥n

---

## üìà M√©tricas de √âxito

### **C√≥mo medir mejoras:**
1. **Precisi√≥n (Precision):** % de licitaciones con match alto que realmente son relevantes
2. **Recall:** % de licitaciones relevantes que se identifican correctamente
3. **F1-Score:** Balance entre precisi√≥n y recall
4. **Feedback del usuario:** Marcar licitaciones como "Relevante" / "No relevante"

### **Objetivo:**
- **Precisi√≥n actual estimada:** ~60-70%
- **Objetivo despu√©s de mejoras:** ~85-90%

---

## üí° Recomendaci√≥n Final

**Empezar con Fase 1 (Mejoras R√°pidas):**
1. Sin√≥nimos en keywords
2. Normalizaci√≥n de entidades
3. Factor de ubicaci√≥n
4. Ajuste por inflaci√≥n

Estas 4 mejoras son **r√°pidas de implementar** y tienen **alto impacto** en la precisi√≥n.

---

**Fecha de creaci√≥n:** 2025-11-17  
**Versi√≥n:** 1.0

